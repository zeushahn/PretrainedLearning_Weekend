{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLaMa에 전이학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-20T02:42:58.286915Z",
     "iopub.status.busy": "2025-09-20T02:42:58.286277Z",
     "iopub.status.idle": "2025-09-20T02:44:30.952313Z",
     "shell.execute_reply": "2025-09-20T02:44:30.951611Z",
     "shell.execute_reply.started": "2025-09-20T02:42:58.286892Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 MB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m564.7/564.7 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m95.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m563.4/563.4 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "bigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\n",
      "bigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\n",
      "bigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# trl(transformers reinforecement learning) : 강화학습을 통해 트랜스포머 언어모델을 미세조정\n",
    "# peft(parameter efficient find tunning) : 대규모 언어 모델을 효율적으로 미세 조정 \n",
    "\n",
    "!pip install -q datasets bitsandbytes trl peft accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-20T02:44:30.953871Z",
     "iopub.status.busy": "2025-09-20T02:44:30.953614Z",
     "iopub.status.idle": "2025-09-20T02:44:40.937448Z",
     "shell.execute_reply": "2025-09-20T02:44:40.936918Z",
     "shell.execute_reply.started": "2025-09-20T02:44:30.953848Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import BitsAndBytesConfig, AutoTokenizer, AutoModelForCausalLM\n",
    "from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-20T02:44:40.938530Z",
     "iopub.status.busy": "2025-09-20T02:44:40.938152Z",
     "iopub.status.idle": "2025-09-20T02:44:41.021404Z",
     "shell.execute_reply": "2025-09-20T02:44:41.020624Z",
     "shell.execute_reply.started": "2025-09-20T02:44:40.938512Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# GPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-20T02:44:41.023196Z",
     "iopub.status.busy": "2025-09-20T02:44:41.022966Z",
     "iopub.status.idle": "2025-09-20T02:44:41.146200Z",
     "shell.execute_reply": "2025-09-20T02:44:41.145674Z",
     "shell.execute_reply.started": "2025-09-20T02:44:41.023179Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 한글 wikipedia 교육용 사용\n",
    "login(\"________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-20T02:44:41.147117Z",
     "iopub.status.busy": "2025-09-20T02:44:41.146770Z",
     "iopub.status.idle": "2025-09-20T02:44:44.316486Z",
     "shell.execute_reply": "2025-09-20T02:44:44.315978Z",
     "shell.execute_reply.started": "2025-09-20T02:44:41.147098Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "412ba155d7fe4037a36175b680e0c750",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/2.25k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72254d8fb40a46bbbd47a25117115de8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "scored_over_3/train-00000-of-00001.parqu(…):   0%|          | 0.00/104M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e7f153dddc54bebb9b751733c1ed90c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/65161 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 데이터셋 로드\n",
    "dataset = load_dataset(\"devngho/korean-wikipedia-edu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-20T02:44:44.317428Z",
     "iopub.status.busy": "2025-09-20T02:44:44.317191Z",
     "iopub.status.idle": "2025-09-20T02:44:44.323046Z",
     "shell.execute_reply": "2025-09-20T02:44:44.322342Z",
     "shell.execute_reply.started": "2025-09-20T02:44:44.317391Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 양자와 설정 : Kaggle에서 안정성을 위한 double_quant 사용\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit = True,\n",
    "    bnb_4bit_quant_type='nf4',\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-20T02:44:44.324383Z",
     "iopub.status.busy": "2025-09-20T02:44:44.324066Z",
     "iopub.status.idle": "2025-09-20T02:44:44.691065Z",
     "shell.execute_reply": "2025-09-20T02:44:44.690272Z",
     "shell.execute_reply.started": "2025-09-20T02:44:44.324358Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# LLaMa3 Token\n",
    "token = \"_________\"\n",
    "model_name = \"meta-llama/Meta-Llama-3.1-8B-Instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-20T02:44:44.692240Z",
     "iopub.status.busy": "2025-09-20T02:44:44.691918Z",
     "iopub.status.idle": "2025-09-20T02:44:52.962595Z",
     "shell.execute_reply": "2025-09-20T02:44:52.961966Z",
     "shell.execute_reply.started": "2025-09-20T02:44:44.692212Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mzeushahn\u001b[0m (\u001b[33mzeushahn-khankong\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "import wandb, os\n",
    "wandb.login(key=\"_______\")\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-20T02:44:52.963716Z",
     "iopub.status.busy": "2025-09-20T02:44:52.963296Z",
     "iopub.status.idle": "2025-09-20T02:44:54.608368Z",
     "shell.execute_reply": "2025-09-20T02:44:54.607700Z",
     "shell.execute_reply.started": "2025-09-20T02:44:52.963699Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "571109de11df4817805e9b10603b3374",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/55.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a02646da3eed4964bd0dccf7de516d43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a6a0a783ce3434881f7c09fa305e7eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 토크나이저 \n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name,\n",
    "    token=token\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-20T02:44:54.610830Z",
     "iopub.status.busy": "2025-09-20T02:44:54.610369Z",
     "iopub.status.idle": "2025-09-20T02:48:18.725457Z",
     "shell.execute_reply": "2025-09-20T02:48:18.724893Z",
     "shell.execute_reply.started": "2025-09-20T02:44:54.610810Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35c175398412445995794712e19eae4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/855 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-20 02:44:57.289520: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1758336297.519978      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1758336297.584801      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff94108d23e14842a357a0a95fb19e5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c2065b0924c429d8582b9dee77d9e27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e50e12b24ae42998a45aeb5ee2cd329",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae524e75f494481885590b3dc872cfe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "043ec95fb20245e68111e64ac7aaf3d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b77ac45074014dada59f43636225427a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "242f8aba5685446b9d19fd719a86994f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc45a27e0d2441618b06789387a851a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/184 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 모델 로드 \n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=quantization_config,\n",
    "    device_map='auto',\n",
    "    token=token,\n",
    "    dtype=torch.float16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-20T02:48:18.726962Z",
     "iopub.status.busy": "2025-09-20T02:48:18.726283Z",
     "iopub.status.idle": "2025-09-20T02:48:18.732125Z",
     "shell.execute_reply": "2025-09-20T02:48:18.731452Z",
     "shell.execute_reply.started": "2025-09-20T02:48:18.726919Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 패딩 토큰 설정\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-20T02:48:18.733566Z",
     "iopub.status.busy": "2025-09-20T02:48:18.732845Z",
     "iopub.status.idle": "2025-09-20T02:48:18.744899Z",
     "shell.execute_reply": "2025-09-20T02:48:18.744176Z",
     "shell.execute_reply.started": "2025-09-20T02:48:18.733541Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'score'],\n",
      "        num_rows: 65161\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-20T02:48:18.745906Z",
     "iopub.status.busy": "2025-09-20T02:48:18.745680Z",
     "iopub.status.idle": "2025-09-20T02:48:19.655902Z",
     "shell.execute_reply": "2025-09-20T02:48:19.655245Z",
     "shell.execute_reply.started": "2025-09-20T02:48:18.745892Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안토니오 그리마니의 문장.\n",
      "**안토니오 그리마니**(1434년 12월 28일 -- 1523년 5월 7일)는 1521년부터 1523년까지의 베네치아 공화국의 도제이다.\n",
      "## 생애\n",
      "그는 베네치아에서 상대적으로 가난한 집안에서 태어났고 소매상인으로서 몇 년을 종사하다 곧 베네치아 내에서 가장 핵심적인 인물 중 한 명이 되었다. 1494년에 그는 베네치아 총사령관으로 임명되어, 평화로운 기간에 아드리아해 연안을 따라 베네치아의 작전을 이끌어야했기 때문에 상대적으로 쉬운 일이었다. 1499년에 베네치아와 오스만 튀르크 제국 사이의 새로운 전쟁이 발발하였으며, 그의 경험 부족은 두 차례의 패배(8월 19일 사피엔차, 6일 뒤인 존키오 )로 이어졌다.\n",
      "그리마니는 사형 놓이게 됐지만 크레스 섬 추방으로 바뀌었다. 하지만 곧 그는 1509년에 로마로 망명했다.\n",
      "그의 아들들의 중재덕에 1509년 베네치아로 돌아갈 수 있었다. 그의 정치적 유대 관계는 곧 그를 가장 핵심적인 행정 자리를 얻게 했고 미래의 도제 자리(1521년 7월 6일)를 만드는 기반을 만들었다.\n",
      "그가 도제 자리에 오르자, 공화국을 1521년 이탈리아 전쟁으로 이끌었고, 프랑수아 1세의 유일한 동맹이였던 그는 그를 버리지 않았다. 그러나 프랑스가 비코카 전투에서 패한 후, 그는 전쟁의 과정에 대하여 염려했고, 그러나 그가 1523년에 사망하면서 그의 후임인 안드레아 그리티는 카를 5세와의 강화 조약을 맺었다.\n",
      "그는 카테리나 로레단(Caterina Loredan)과 혼인했다. 그의 아들인 도메니코 그리마니는 1493년에 추기경이 되었다.\n"
     ]
    }
   ],
   "source": [
    "print(dataset['train']['text'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LoraConfig\n",
    ": LoRa기법을 사용해 모델에 미세 조정할때 필요한 설정을 정의하는 클래스 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-20T02:48:19.657182Z",
     "iopub.status.busy": "2025-09-20T02:48:19.656882Z",
     "iopub.status.idle": "2025-09-20T02:48:20.028966Z",
     "shell.execute_reply": "2025-09-20T02:48:20.028391Z",
     "shell.execute_reply.started": "2025-09-20T02:48:19.657156Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from peft import LoraConfig\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    r=128,\n",
    "    lora_alpha=4,\n",
    "    lora_dropout=0.1,\n",
    "    task_type='CAUSAL_LM'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SFT Trainer를 통한 미세 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-20T02:48:20.029845Z",
     "iopub.status.busy": "2025-09-20T02:48:20.029636Z",
     "iopub.status.idle": "2025-09-20T02:48:21.354973Z",
     "shell.execute_reply": "2025-09-20T02:48:21.354220Z",
     "shell.execute_reply.started": "2025-09-20T02:48:20.029828Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from trl import SFTTrainer, SFTConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-20T02:48:21.356028Z",
     "iopub.status.busy": "2025-09-20T02:48:21.355778Z",
     "iopub.status.idle": "2025-09-20T02:48:21.404758Z",
     "shell.execute_reply": "2025-09-20T02:48:21.404222Z",
     "shell.execute_reply.started": "2025-09-20T02:48:21.356004Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "training_args = SFTConfig(\n",
    "    output_dir = \".\",\n",
    "    per_device_train_batch_size=1, #epoch\n",
    "    gradient_accumulation_steps = 5, \n",
    "    learning_rate=2e-4,\n",
    "    max_steps=500,\n",
    "    warmup_steps=100,\n",
    "    logging_steps=100,\n",
    "    fp16=True,\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    seed=42,\n",
    "    max_length=128,\n",
    "    dataset_text_field= 'text'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-20T02:48:21.405659Z",
     "iopub.status.busy": "2025-09-20T02:48:21.405461Z",
     "iopub.status.idle": "2025-09-20T02:50:20.820328Z",
     "shell.execute_reply": "2025-09-20T02:50:20.819692Z",
     "shell.execute_reply.started": "2025-09-20T02:48:21.405643Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "312a557edc294c3a975dd734d056a186",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding EOS to train dataset:   0%|          | 0/65161 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b4d052b8cbc42c5aec6072656f6f77e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/65161 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38350be8cb914b64814cf3d7ef753a70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating train dataset:   0%|          | 0/65161 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Trainder 설정\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    processing_class = tokenizer, # tokenizer = tokenizer\n",
    "    args = training_args,\n",
    "    peft_config = peft_config,\n",
    "    train_dataset=dataset['train']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
